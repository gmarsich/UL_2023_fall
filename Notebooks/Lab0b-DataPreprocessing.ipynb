{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Preprocessing\n",
    "\n",
    "We will investigate common practices of data preprocessing with a toy example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/titanic3.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()   #age, fare, cabin, embarked, boat, body, home.dest clearly have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() #you can check it also in this way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to decide how to handle the dataset. A first consideration can be made on the usefulness of the presented columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns Name, Ticket, Cabin, Boat, Body, Home.dest\n",
    "df = df.drop([\"name\",\"ticket\",\"cabin\",\"boat\",\"body\", \"home.dest\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have to deal with missing data. We can choose either to remove the rows that present missing data (but we risk losing a lot of information) or impute the missing values.\n",
    "\n",
    "If you want to remove the rows with missing values you can simply type `df = df.dropna()`. We will proceed with the imputation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].fillna(df['age'].mean())  #impute the mean value of the column for the missing data\n",
    "df['fare'] = df['fare'].fillna(df['fare'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can preprocess the categorical data, as most models are not able to handle them explicitly we resort to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['pclass']), pd.get_dummies(df['sex']), pd.get_dummies(df['embarked'])], axis=1) #concatenate column-wise\n",
    "df.drop([\"pclass\",\"sex\",\"embarked\"], axis=1, inplace=True) #remove original columns, keep only the dummy encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()   #we can see the new columns were added"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else that can be done while preprocessing a dataset is the normalization of the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will treat 'age' and 'fare' \n",
    "#sibsp' and 'parch' represent the number of sibling/spouses or parents/children aboard the ship, and can be left untouched\n",
    "\n",
    "#for example, we can choose to divide by the absolute value of the maximum in order to have features ranging in [0,1]\n",
    "def absolute_maximum_scaler(series):\n",
    "    return series/series.abs().max()\n",
    "\n",
    "for col in ['age', 'fare']:\n",
    "    df[col] = absolute_maximum_scaler(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, you would usually separate the response variable from the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['survived']\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "#or you could write\n",
    "#y = df['survived']\n",
    "#X = df.drop(['survived'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44a886966501868c0cbc0c8bdfb11650a1a570e0fac53b84b354b7450ba02671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
